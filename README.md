# natural-language-processing-tensorflow
Natural Language processing in tensorflow

## Word Encoding

![image](images/2.png)

## Same With ASCI CODE

With asci analysis the word **LISTEN** and *SILENT** are the same value but the two words are very differents of meaning.
![image](images/3.png)

## How Sentiment Analysis Work

![image](images/4.png)

* How we can observed the similarity between two words

![image](images/5.png)

* Now if we look at the two sentences to determine the difference between two sentences.

![image](images/6.png)


## How To Analyse The Synthaxe

![image](images/1.png)

## Creating The List Of Sequences

![image](images/7.png)

## Complete Analysis Corpus

![image](images/8.png)

## Padding Sequences

![image](images/9.png)

## Result Of Padding  Sequence 

![image](images/10.png)

## Personnalize Padding

![image](images/11.png)

## Sarcasm in News Headlines Dataset by Rishabh Misra

[https://rishabhmisra.github.io/publications/](https://rishabhmisra.github.io/publications/)

## How To Load Sarcasm Dataset

![image](images/12.png)

## How To Analysis Sarcasm Dataset

![image](images/13.png)

## Sarcasm Detection

* [https://www.kaggle.com/datasets/rmisra/news-headlines-dataset-for-sarcasm-detection](https://www.kaggle.com/datasets/rmisra/news-headlines-dataset-for-sarcasm-detection)

## Build-in Dataset In Tensorflow

![image](images/14.png)

## Dataset

![image](images/15.png)

## Verify Tensorflow Version
![image](images/16.png)

## Import Tensorflow Dataset

![image](images/17.png)

## Split data

![image](images/18.png)

![image](images/19.png)

![image](images/20.png)

![image](images/21.png)

## Tokenizer

![image](images/22.png)

## Model

![image](images/23.png)

OR

![image](images/24.png)

![image](images/25.png)

## Training Model

![image](images/26.png)

## Expect Layer

![image](images/27.png)

## Reverse Word Index

![image](images/28.png)

## Vecteor In Embedded Data

![image](images/29.png)

## Download In Colab

![image](images/30.png)

![image](images/30.png)

## Model For Sarcasm Dataset

### Importation of Tokenizer And Pad_sequence

![image](images/31.png)

### Hyper Parameters

![image](images/32.png)

### Download Sarcasm Dataset

![image](images/33.png)

### Loading Sarcasm Dataset

![image](images/34.png)

### Building a classifier for the sarcasm dataset

![image](images/35.png)

### Sequence Dataset

![image](images/36.png)

### Create A Model

![image](images/37.png)

### Summarization Of Model

![image](images/38.png)

### Training The Model

![image](images/39.png)

### Plotting The Result Of Training

![image](images/40.png)

![image](images/41.png)

## TensorFlow datasets

* [https://github.com/tensorflow/datasets/tree/master/docs/catalog](https://github.com/tensorflow/datasets/tree/master/docs/catalog)

* [https://www.tensorflow.org/datasets/catalog/overview](https://www.tensorflow.org/datasets/catalog/overview)

## Subwords text encoder

* [https://www.tensorflow.org/datasets/api_docs/python/tfds/deprecated/text/SubwordTextEncoder](https://www.tensorflow.org/datasets/api_docs/python/tfds/deprecated/text/SubwordTextEncoder)

## Diving into the code: Encode And Decode

![image](images/42.png)

![image](images/43.png)

## Classify Sub Word

![image](images/44.png)

![image](images/45.png)

![image](images/46.png)


## RNN

The neural Network is kind a function that we can a data and label it give a rules

![image](images/47.png)

![image](images/48.png)

![image](images/49.png)

## How RNN Work

![image](images/52.png)

## Visualize A Sequence

![image](images/50.png)

![image](images/51.png)

## More About RNN

* [https://www.coursera.org/lecture/nlp-sequence-models/deep-rnns-ehs0S](https://www.coursera.org/lecture/nlp-sequence-models/deep-rnns-ehs0S)

## How To Understang The Context Of Word

![image](images/53.png)

## Uni Directional Cell State

![image](images/54.png)

## Bi Directional Cell State

![image](images/55.png)

## How To Implement LSTM in Tensorflow

![image](images/56.png)

## How To Stack LSTM

![image](images/57.png)


## More About LSTMs

* [https://www.coursera.org/lecture/nlp-sequence-models/long-short-term-memory-lstm-KXoay](https://www.coursera.org/lecture/nlp-sequence-models/long-short-term-memory-lstm-KXoay)


## Generation A New Text Process

![image](images/58.png)

### Preparing the training data

![image](images/59.png)

![image](images/60.png)

![image](images/61.png)

![image](images/62.png)

![image](images/63.png)

## Userful Link

* [https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer)
  
* [https://ai.stanford.edu/~amaas/data/sentiment/](https://ai.stanford.edu/~amaas/data/sentiment/)

* [https://github.com/tensorflow/datasets/tree/master/docs/catalog](https://github.com/tensorflow/datasets/tree/master/docs/catalog) 

* [https://www.tensorflow.org/datasets/catalog/overview](https://www.tensorflow.org/datasets/catalog/overview)

